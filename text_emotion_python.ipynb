{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RM_UPDATED.ipynb",
      "provenance": [],
      "mount_file_id": "1u_01jGtiTu5vPui9AINto2B10BzSp1n5",
      "authorship_tag": "ABX9TyN2/V4E6DqlKZjLjkQ4Ubj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nidhizala1426/Text_based_emotion_detection_python/blob/main/text_emotion_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEz96o_BTEX_"
      },
      "source": [
        "Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiSbJvefTKE2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7t7tZarTWSw"
      },
      "source": [
        "Import the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhO_RguQTMd_"
      },
      "source": [
        "text_data = pd.read_csv('/content/drive/MyDrive/text_emotion.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umGxsrC-TZSr"
      },
      "source": [
        "Cleanup Data by removing Unecessary Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaF1Et3TeSk"
      },
      "source": [
        "text_data = text_data.drop(text_data[text_data.sentiment == 'anger'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'hate'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'surprise'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'fun'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'boredom'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'empty'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'relief'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'worry'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'enthusiasm'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'love'].index)\n",
        "text_data = text_data.drop(text_data[text_data.sentiment == 'neutral'].index)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "j1cWZLuctpM-",
        "outputId": "a4dea60a-429e-4ea9-9e86-58302cf2b37a"
      },
      "source": [
        "text_data.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>coolfunky</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1956968487</td>\n",
              "      <td>sadness</td>\n",
              "      <td>ShansBee</td>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1956969035</td>\n",
              "      <td>sadness</td>\n",
              "      <td>nic0lepaula</td>\n",
              "      <td>@charviray Charlene my love. I miss you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1956969172</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Ingenue_Em</td>\n",
              "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id  ...                                            content\n",
              "1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696  ...                Funeral ceremony...gloomy friday...\n",
              "6  1956968487  ...  I should be sleep, but im not! thinking about ...\n",
              "8  1956969035  ...            @charviray Charlene my love. I miss you\n",
              "9  1956969172  ...         @kelcouch I'm sorry  at least it's Friday?\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbjS-rwITZOD"
      },
      "source": [
        "PreProcessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCF1jSZ4UMgi",
        "outputId": "89def70a-8e1e-4452-f72d-4cf046bebe0f"
      },
      "source": [
        "import nltk  \n",
        "nltk.download()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n",
            "    Downloading package wordnet to /root/nltk_data...\n",
            "      Package wordnet is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZEEurG_UdIQ"
      },
      "source": [
        "Making Letters Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNjoayoNUXPC"
      },
      "source": [
        "text_data['content'] = text_data['content'].apply(lambda p: \" \".join(p.lower() for p in p.split()))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRvNEXNSUisE"
      },
      "source": [
        "Stopword Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNmsztcYUhBo"
      },
      "source": [
        "stopwords1 = stopwords.words('english')\n",
        "text_data['content'] = text_data['content'].apply(lambda p: \" \".join(p for p in p.split() if p not in stopwords1))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etIFYDS6UxJs"
      },
      "source": [
        "Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap8qc6RpW4nP"
      },
      "source": [
        "text_data['content'] = text_data['content'].str.replace('[^\\w\\s]',' ')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApzMxTiW5zl"
      },
      "source": [
        "Finding top rarest words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPnwms9CuNzZ"
      },
      "source": [
        "frequency = pd.Series(' '.join(text_data['content']).split()).value_counts()[-10000:]\n",
        "frequency = list(frequency.index)\n",
        "text_data['content'] = text_data['content'].apply(lambda p: \" \".join(p for p in p.split() if p not in frequency))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTMx4d4Vugfv"
      },
      "source": [
        "Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBwNG6z_uiJ1"
      },
      "source": [
        "#Labels sad=1 & happy=0\n",
        "labels = preprocessing.LabelEncoder()\n",
        "y = labels.fit_transform(text_data.sentiment.values)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnOawz-Yut_T"
      },
      "source": [
        "Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26qzv08uuvKB"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(text_data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arYaoSRDvELT"
      },
      "source": [
        "###TFIDF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJi38sCRvHcu"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
        "X_train_vect_tfidf = tfidf_vect.fit_transform(X_train)\n",
        "X_val_vect_tfidf = tfidf_vect.fit_transform(X_val)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnpF1H5DvUNv"
      },
      "source": [
        "##Count Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X7-SNt2vWNB"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect_count = CountVectorizer(analyzer='word')\n",
        "vect_count.fit(text_data['content'])\n",
        "count_X_train =  vect_count.transform(X_train)\n",
        "count_X_val =  vect_count.transform(X_val)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBChYl2uvj4u"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKbWaV5qvmCv"
      },
      "source": [
        "##Naive Bayes TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP29ErNdvuyO",
        "outputId": "baa6e908-714d-42c7-9068-325091fd4def"
      },
      "source": [
        "naive = MultinomialNB()\n",
        "naive.fit(X_train_vect_tfidf, y_train)\n",
        "y_pred = naive.predict(X_val_vect_tfidf)\n",
        "print('naive bayes tfidf accuracy %s' % accuracy_score(y_pred, y_val))\n",
        "print(classification_report(y_val, y_pred,labels=[0,1]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive bayes tfidf accuracy 0.5481695568400771\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.54      0.54       521\n",
            "           1       0.55      0.56      0.55       517\n",
            "\n",
            "    accuracy                           0.55      1038\n",
            "   macro avg       0.55      0.55      0.55      1038\n",
            "weighted avg       0.55      0.55      0.55      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBKuh78YvqkP"
      },
      "source": [
        "##Naive Bayes Count vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6McarqOwdnC",
        "outputId": "7366d559-0a06-49c8-91a1-09a74910ae86"
      },
      "source": [
        "naive_c = MultinomialNB()\n",
        "naive_c.fit(count_X_train, y_train)\n",
        "y_pred_c = naive_c.predict(count_X_val)\n",
        "print('naive bayes count vectors accuracy %s' % accuracy_score(y_pred_c, y_val))\n",
        "print(classification_report(y_val, y_pred_c,labels=[0,1]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive bayes count vectors accuracy 0.7716763005780347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.77       521\n",
            "           1       0.77      0.78      0.77       517\n",
            "\n",
            "    accuracy                           0.77      1038\n",
            "   macro avg       0.77      0.77      0.77      1038\n",
            "weighted avg       0.77      0.77      0.77      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gYguB5ZvwzF"
      },
      "source": [
        "##Linear SVM TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvM-pNy0weJh",
        "outputId": "8afe7dbd-1479-4fd7-b0f0-1f8855316878"
      },
      "source": [
        "linear_svm_tf = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "linear_svm_tf.fit(X_train_vect_tfidf, y_train)\n",
        "y_pred_svm = linear_svm_tf.predict(X_val_vect_tfidf)\n",
        "print('svm using tfidf accuracy %s' % accuracy_score(y_pred_svm, y_val))\n",
        "print(classification_report(y_val, y_pred_svm,labels=[0,1]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm using tfidf accuracy 0.5317919075144508\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.43      0.48       521\n",
            "           1       0.52      0.64      0.58       517\n",
            "\n",
            "    accuracy                           0.53      1038\n",
            "   macro avg       0.53      0.53      0.53      1038\n",
            "weighted avg       0.53      0.53      0.53      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfv-ugSCvzw0"
      },
      "source": [
        "##Linear SVM Count Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mxc6tkZwfBf",
        "outputId": "a87eaf8b-7b70-4ddf-ae29-267002d7558b"
      },
      "source": [
        "linear_svm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "linear_svm.fit(count_X_train, y_train)\n",
        "y_pred_sc = linear_svm.predict(count_X_val)\n",
        "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred_sc, y_val))\n",
        "print(classification_report(y_val, y_pred_sc,labels=[0,1]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lsvm using count vectors accuracy 0.7928709055876686\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.80       521\n",
            "           1       0.80      0.77      0.79       517\n",
            "\n",
            "    accuracy                           0.79      1038\n",
            "   macro avg       0.79      0.79      0.79      1038\n",
            "weighted avg       0.79      0.79      0.79      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVQV6LHKv21X"
      },
      "source": [
        "##Logistic Regression TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ-Oq8qpwf2Z",
        "outputId": "33585db0-7fe8-4fde-8df5-dee66c6fa8af"
      },
      "source": [
        "logistic_reg = LogisticRegression(C=1)\n",
        "logistic_reg.fit(X_train_vect_tfidf, y_train)\n",
        "y_pred_LR1 = logistic_reg.predict(X_val_vect_tfidf)\n",
        "print('log reg tfidf accuracy %s' % accuracy_score(y_pred_LR1, y_val))\n",
        "print(classification_report(y_val, y_pred_LR1,labels=[0,1]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log reg tfidf accuracy 0.5260115606936416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.47      0.50       521\n",
            "           1       0.52      0.58      0.55       517\n",
            "\n",
            "    accuracy                           0.53      1038\n",
            "   macro avg       0.53      0.53      0.52      1038\n",
            "weighted avg       0.53      0.53      0.52      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLU31GT8wNky"
      },
      "source": [
        "##Logistic Regression Count Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZiXuVzWwgTr",
        "outputId": "f558bbb3-dae1-438f-d514-67411259ec46"
      },
      "source": [
        "logistic_reg_c = LogisticRegression(C=1)\n",
        "logistic_reg_c.fit(count_X_train, y_train)\n",
        "y_pred_lr = logistic_reg_c.predict(count_X_val)\n",
        "print('log reg count vectors accuracy %s' % accuracy_score(y_pred_lr, y_val))\n",
        "print(classification_report(y_val, y_pred_lr,labels=[0,1]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log reg count vectors accuracy 0.7861271676300579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79       521\n",
            "           1       0.80      0.76      0.78       517\n",
            "\n",
            "    accuracy                           0.79      1038\n",
            "   macro avg       0.79      0.79      0.79      1038\n",
            "weighted avg       0.79      0.79      0.79      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wIGwkK7wS4q"
      },
      "source": [
        "##Random forest TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMXR5npWwgnr",
        "outputId": "b624eefd-9558-44b9-9dac-17c8d484feb8"
      },
      "source": [
        "random_f = RandomForestClassifier(n_estimators=500)\n",
        "random_f.fit(X_train_vect_tfidf, y_train)\n",
        "y_pred_rf = random_f.predict(X_val_vect_tfidf)\n",
        "print('random forest tfidf accuracy %s' % accuracy_score(y_pred_rf, y_val))\n",
        "print(classification_report(y_val, y_pred_rf,labels=[0,1]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest tfidf accuracy 0.5269749518304432\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.54      0.53       521\n",
            "           1       0.53      0.51      0.52       517\n",
            "\n",
            "    accuracy                           0.53      1038\n",
            "   macro avg       0.53      0.53      0.53      1038\n",
            "weighted avg       0.53      0.53      0.53      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn3V4U-UwWok"
      },
      "source": [
        "##Random Forest Count vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzTkhw9lwg9G",
        "outputId": "1645dfee-7f68-4bd1-a958-ca3bc653f4d5"
      },
      "source": [
        "rand_f = RandomForestClassifier(n_estimators=500)\n",
        "rand_f.fit(count_X_train, y_train)\n",
        "y_pred_rf2 = rand_f.predict(count_X_val)\n",
        "print('random forest with count vectors accuracy %s' % accuracy_score(y_pred_rf2, y_val))\n",
        "print(classification_report(y_val, y_pred_rf2,labels=[0,1]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest with count vectors accuracy 0.75626204238921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76       521\n",
            "           1       0.76      0.74      0.75       517\n",
            "\n",
            "    accuracy                           0.76      1038\n",
            "   macro avg       0.76      0.76      0.76      1038\n",
            "weighted avg       0.76      0.76      0.76      1038\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TnZlaYQI4hu"
      },
      "source": [
        "##Single Statement Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlxXSlGtvn-9",
        "outputId": "662fd66c-9da1-4566-c412-d9e8cf0c5809"
      },
      "source": [
        "from textblob import Word\n",
        "tweet1 = pd.DataFrame(['Today is a good day', 'It breaks my heart'])\n",
        "tweet1[0] = tweet1[0].str.replace('[^\\w\\s]',' ')\n",
        "stopwords2 = stopwords.words('english')\n",
        "tweet1[0] = tweet1[0].apply(lambda a: \" \".join(a for a in a.split() if a not in stopwords2))\n",
        "tweet1[0] = tweet1[0].apply(lambda b: \" \".join([Word(word).lemmatize() for word in b.split()]))\n",
        "tweets_counting = vect_count.transform(tweets[0])\n",
        "#Predicting the emotion of the tweet using our already trained linear SVM\n",
        "tweets_prediction = linear_svm.predict(tweets_counting)\n",
        "print(\"Simple prediction sentence\")\n",
        "print(tweets_prediction)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple prediction sentence\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmw2kUx5J5Qq"
      },
      "source": [
        "**References :**\n",
        "\n",
        "X. (2020, May 23). Applied Machine Learning: Part 3 - The Research Nest. Medium. https://medium.com/the-research-nest/applied-machine-learning-part-3-3fd405842a18"
      ]
    }
  ]
}